{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/miniconda3/envs/LLM/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch  \n",
    "\n",
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings  \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "import faiss\n",
    "import os\n",
    "import joblib\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from faiss import IndexFlatL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Simon Zhong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 16:52:12.897292: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-18 16:52:12.904203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:483] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1723971132.911351 2304717 cuda_dnn.cc:8458] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1723971132.913475 2304717 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-18 16:52:12.919698: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-18 16:52:13.427152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at /home/simon/disk1/Simon/Code/COLING/models/BAAI/bge-reranker-v2-m3 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 32.89it/s]\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n",
      "Extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 196.11it/s]\n",
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "#only in test condition import\n",
    "from multilinggual_dataset_processing.data_processing import EmbeddingModel\n",
    "from retriever_module.retriever import aggregate_vstores,prompt_router,llm_wrapper,ChineseTemplate_0,EnglishTemplate_0,EnglishTemplate\n",
    "import importlib\n",
    "\n",
    "\n",
    "embedder = EmbeddingModel(model_name_or_path=\"/home/simon/disk1/Simon/Code/COLING/models/BAAI/bge-reranker-v2-m3\")\n",
    "embed_dims = embedder.encode(\"test\").shape[1] # dim of embedder\n",
    "# EmbeddingModel = importlib.import_module(\"data_processing\").EmbeddingModel\n",
    "docstore = [FAISS.load_local(folder_path=\"/home/simon/disk1/Simon/Code/COLING/RAG_data/FAISS_DB/\", embeddings=embedder,allow_dangerous_deserialization=True)]\n",
    "# 数据库整合\n",
    "docstore = aggregate_vstores(docstore,embedder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    # ChatPromptTemplate.from_template(EnglishTemplate) | ChatOpenAI(temperature=0) | StrOutputParser() \n",
    "    ChatPromptTemplate.from_template(EnglishTemplate_0) | llm_wrapper(model_path_or_name=\"/home/simon/disk1/Simon/Code/LLM/models/meta-llama/Llama-2-7b-hf\") | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_docs_for_retrieval.invoke(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to Together endpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.85s/it]\n",
      "/home/simon/miniconda3/envs/LLM/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/simon/miniconda3/envs/LLM/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "retriever = docstore.as_retriever()\n",
    "retrieval_chain = generate_docs_for_retrieval |RunnableLambda(lambda x : [x])| retriever \n",
    "\n",
    "# example: \n",
    "question = \"whta is AI LAW\"\n",
    "retireved_docs = retrieval_chain.invoke({\"query\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Custom HuggingFace Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llama_llm =  llm_wrapper(model_path_or_name=\"/home/simon/disk1/Simon/Code/LLM/models/meta-llama/Llama-2-7b-hf\")\n",
    "chain_rag = (\n",
    "    {\"query\": RunnablePassthrough(),\"context\":retriever}\n",
    "    | ChatPromptTemplate.from_template(EnglishTemplate)\n",
    "    | llama_llm\n",
    "    | StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To do \n",
    "- ADD CUSTOM llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to Together endpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what is AI LAW?\\n Hinweis: Die Anmeldung ist nur in englischer Sprache möglich.\\nThe AI LAW is a 3-day conference on Artificial Intelligence and Law. It is the first conference of its kind in Europe and will take place in Vienna, Austria, on 21-23 June 2018.\\nThe AI LAW is a joint initiative of the University of Vienna, the University of Graz, the University of Salzburg,'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_llm.invoke(\"what is AI LAW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to Together endpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what is ai law?\\n nobody is going to be able to tell you what is ai law.\\n\\nComment: @DmitryGrigoryev I\\'m not sure what you mean by \"what is ai law\". I\\'m not sure what you mean by \"what is ai law\".\\n\\nComment: @DmitryGrigoryev I\\'m not sure what you mean by \"what is ai law\".\\n\\nComment: @DmitryGrigoryev I\\'m'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_llm(\"what is ai law\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to Together endpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Human: \\nYou are a very good English native speaker. You are great at answering questions in English. You are so good because you are able to break down hard problems into their component parts, answer the component parts, and then put them together in English to answer the broader question.\\nHere is the provided context:\\n[Document(page_content='high-risk AI system. The declaration shall contain all the information required for identification of the Union harmonisation legislation to which the declaration relates. ', metadata={'source': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW/English.doc', 'category_depth': 0, 'file_directory': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW', 'filename': 'English.doc', 'last_modified': '2024-06-15T01:11:06', 'page_number': 69, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}), Document(page_content='7.\\\\tNotified bodies shall have procedures for the performance of activities which take due account of the size of an undertaking, the sector in which it operates, its structure, the degree of complexity of the AI system in question.', metadata={'source': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW/English.doc', 'category_depth': 0, 'file_directory': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW', 'filename': 'English.doc', 'last_modified': '2024-06-15T01:11:06', 'page_number': 61, 'languages': ['eng'], 'parent_id': '9565edefad3a5c79ed472f6b10041ac4', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}), Document(page_content='AI suppliers should benefit from a minimal but clear set of requirements, creating legal certainty and ensuring access to the entire single market.', metadata={'source': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW/English.doc', 'category_depth': 0, 'file_directory': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW', 'filename': 'English.doc', 'last_modified': '2024-06-15T01:11:06', 'page_number': 90, 'languages': ['eng'], 'parent_id': '007cd5fb104eedffada34afa05c23cc1', 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'NarrativeText'}), Document(page_content='requirements for high-risk Ai systems', metadata={'source': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW/English.doc', 'category_depth': 0, 'file_directory': '/home/simon/disk1/Simon/Code/COLING/Multilingual AI LAW', 'filename': 'English.doc', 'last_modified': '2024-06-15T01:11:06', 'page_number': 47, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'category': 'Title'})]\\nHere is a question:\\nwhen is the AI LAW published\\n\\nI have tried to answer this question in English, but I am not sure if I have done it correctly.\\n\\n\\\\begin{code}\\nimport spacy\\nfrom spacy.tokens import Token\\n\\nnlp = spacy.load('en_core_web_md')\\n\\ndoc = nlp(text)\\n\\nfor token in doc:\\n    if token.text == 'AI LAW':\\n        print(token.text)\\n\\\\end\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_rag.invoke(\"when is the AI LAW published\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Custom OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TencentCloudSDKException] code:AuthFailure.SecretIdNotFound message:SecretId不存在，请输入正确的密钥。 requestId:d38e52dd-73c4-445b-a74e-18aefa31c540\n"
     ]
    }
   ],
   "source": [
    "from generate_module.generate import Generate,API_LLM_library\n",
    "openai_35 = API_LLM_library(api_name=\"gpt-3.5-turbo\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to  endpoint.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"AI's Law refers to the legal and ethical rules that govern the development and use of artificial intelligence (AI). This is relatively new legal territory, and specific legislation can vary greatly depending on location and context. However, there are some general principles that many agree should guide AI law:\\n\\n1. Transparency: AI systems should be transparent and explainable. People should be able to understand how the system works and how decisions are made.\\n\\n2. Accountability: If an AI system causes harm, there should be a clear party responsible. This could be the developer, the user, or even the AI system itself in some cases.\\n\\n3. Privacy: AI systems should respect the privacy of individuals. This includes not collecting or using personal data without permission.\\n\\n4. Fairness: AI systems should not discriminate or show bias. This means they should be designed and trained in a way that does not favor certain groups over others.\\n\\n5. Security: AI systems should be secure and not easily hackable.\\n\\nIt's important to note that laws regarding AI are still in flux and are evolving as the technology progresses.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_35.invoke(\"what is the AI's LAW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request hyllm err:HTTPConnectionPool(host='hunyuanapi.woa.com', port=80): Max retries exceeded with url: /openapi/v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f191d60dcc0>, 'Connection to hunyuanapi.woa.com timed out. (connect timeout=60)'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"HTTPConnectionPool(host='hunyuanapi.woa.com', port=80): Max retries exceeded with url: /openapi/v1/chat/completions (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x7f191d60dcc0>, 'Connection to hunyuanapi.woa.com timed out. (connect timeout=60)'))\",\n",
       " \"AI Law refers to the area of law that deals with the legal implications of Artificial Intelligence. This includes aspects like regulation of AI and its applications, intellectual property rights of AI systems, liability issues with AI, data privacy and protection concerns associated with AI, and more. Given the widespread use and impact of AI in today's world, there is a need for specific laws and regulations to govern its use and address potential legal and ethical issues.\",\n",
       " 'AI Law, also known as Artificial Intelligence Law, is a branch of law that addresses the legal concerns and challenges associated with AI (Artificial Intelligence), which includes autonomous systems, machine learning, robotics, and more. It deals with issues such as data protection and privacy, intellectual property rights, liability and ethics associated with AI technology. It\\'s still a developing field because the technology is evolving very rapidly and outpacing current legal frameworks. Some specific areas of interest within AI Law include accountability for AI decisions, \"personhood\" or legal status of AI, and issues of discrimination or bias in AI systems.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_library = Generate()\n",
    "LLM_library.get_gpt_answer(\"what is AI LAW?\",\"what is AI LAW?\",\"what is AI LAW?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_chain_rag = (\n",
    "    {\"query\": RunnablePassthrough(),\"context\":retriever}\n",
    "    | ChatPromptTemplate.from_template(EnglishTemplate)\n",
    "    | openai_35\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making API call to  endpoint.\n"
     ]
    }
   ],
   "source": [
    "A = openai_chain_rag.invoke(\"what is AI LAW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Law refers to the legal and regulatory norms, rules, and principles applicable to artificial intelligence (AI). It involves the establishment of a legal framework that governs the use, creation, distribution, and consequences of AI technologies and applications. The documents provided touch upon topics such as AI regulatory sandboxes and certifications which are part of this broader area of law. For instance, an AI regulatory sandbox is a testing environment used to experiment with AI technologies within a controlled setting under the oversight of competent authorities. It is considered vital for the promotion of AI, as indicated in one of the documents.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Custom Hunyuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as openai ,changing the api_name value to \"hunyuan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "- multilingual rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_KL(p||q) = 0.038590757823086505, D_KL(q||p) = 0.04613902821563383\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "  \n",
    "def kl_divergence(p, q):  \n",
    "    \"\"\"  \n",
    "    计算KL散度 D_KL(p||q)  \n",
    "    :param p: 第一个概率分布，numpy数组  \n",
    "    :param q: 第二个概率分布，numpy数组  \n",
    "    :return: KL散度的值  \n",
    "    \"\"\"  \n",
    "    # 确保p和q都是概率分布，即它们的和都为1  \n",
    "    p = p / np.sum(p)  \n",
    "    q = q / np.sum(q)  \n",
    "      \n",
    "    # 避免对0取对数，将0替换为一个非常小的正数（如1e-15）  \n",
    "    p = np.clip(p, 1e-15, 1)  \n",
    "    q = np.clip(q, 1e-15, 1)  \n",
    "      \n",
    "    # 计算KL散度  \n",
    "    return np.sum(p * np.log(p / q))  \n",
    "  \n",
    "# 示例  \n",
    "p = np.array([0.1, 0.2, 0.7,0.1, 0.2, 0.7,0.1, 0.2, 0.7,0.1, 0.2, 0.7])  \n",
    "q = np.array([0.2, 0.2, 0.6,0.2, 0.2, 0.6,0.2, 0.2, 0.6,0.2, 0.2, 0.6])  \n",
    "kl_pq = kl_divergence(p, q)  \n",
    "kl_qp = kl_divergence(q, p)  \n",
    "print(f\"D_KL(p||q) = {kl_pq}, D_KL(q||p) = {kl_qp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSD(p, q) = 0.04594059884701647\n"
     ]
    }
   ],
   "source": [
    "def js_divergence(p, q):  \n",
    "    \"\"\"  \n",
    "    计算JS散度  \n",
    "    :param p: 第一个概率分布，numpy数组  \n",
    "    :param q: 第二个概率分布，numpy数组  \n",
    "    :return: JS散度的值  \n",
    "    \"\"\"  \n",
    "    # 确保p和q都是概率分布  \n",
    "    p = p / np.sum(p)  \n",
    "    q = q / np.sum(q)  \n",
    "      \n",
    "    # 计算混合分布M  \n",
    "    m = 0.5 * (p + q)  \n",
    "      \n",
    "    # 计算KL散度 D_KL(p||m) 和 D_KL(q||m)  \n",
    "    kl_pm = np.sum(p * np.log(p / m))  \n",
    "    kl_qm = np.sum(q * np.log(q / m))  \n",
    "      \n",
    "    # 计算JS散度  \n",
    "    return 0.5 * (kl_pm + kl_qm)  \n",
    "  \n",
    "# 示例  \n",
    "p = np.array([0.1, 0.2, 0.7])  \n",
    "q = np.array([0.0008, 0.9, 1.6])  \n",
    "js_pq = js_divergence(p, q)  \n",
    "print(f\"JSD(p, q) = {js_pq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[90.79102325439453, 71.17613983154297], [72.53498840332031, 90.14605712890625]]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "# Each input text should start with \"query: \" or \"passage: \", even for non-English texts.\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = ['query: how much protein should a female eat',\n",
    "               'query: 南瓜的家常做法',\n",
    "               \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "               \"passage: 1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法: 1、南瓜用刀薄薄的削去表面一层皮,用勺子刮去瓤 2、擦成细丝(没有擦菜板就用刀慢慢切成细丝) 3、锅烧热放油,入葱花煸出香味 4、入南瓜丝快速翻炒一分钟左右,放盐、一点白糖和鸡精调味出锅 2.香葱炒南瓜 原料:南瓜1只 调料:香葱、蒜末、橄榄油、盐 做法: 1、将南瓜去皮,切成片 2、油锅8成热后,将蒜末放入爆香 3、爆香后,将南瓜片放入,翻炒 4、在翻炒的同时,可以不时地往锅里加水,但不要太多 5、放入盐,炒匀 6、南瓜差不多软和绵了之后,就可以关火 7、撒入香葱,即可出锅\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('/home/simon/disk1/Simon/Code/LLM/models/intfloat/multilingual-e5-base')\n",
    "model = AutoModel.from_pretrained('/home/simon/disk1/Simon/Code/LLM/models/intfloat/multilingual-e5-base')\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "print(scores.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
